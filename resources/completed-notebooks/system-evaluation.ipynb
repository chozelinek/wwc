{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions, exceptions, list comprehensions and PRF\n",
    "====\n",
    "\n",
    "\n",
    "A spam-classifier where it outputs spam (y=1) and non-spam (y=0). 90% of the time it's non-spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = gold_data = [1] + [0] * 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's say you have a classiifer that always predicts spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spam = [1] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function for precision, recall, f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(gold, predicted):\n",
    "  true_pos = sum(1 for p,g in zip(predicted, gold) if p==1 and g==1)\n",
    "  true_neg = sum(1 for p,g in zip(predicted, gold) if p==0 and g==0)\n",
    "  false_pos = sum(1 for p,g in zip(predicted, gold) if p==1 and g==0)\n",
    "  false_neg = sum(1 for p,g in zip(predicted, gold) if p==0 and g==1)\n",
    "  try:\n",
    "    recall = true_pos / float(true_pos + false_neg)\n",
    "  except:\n",
    "    recall = 0\n",
    "  try:\n",
    "    precision = true_pos / float(true_pos + false_pos)\n",
    "  except:\n",
    "    precision = 0\n",
    "  try:\n",
    "    fscore = 2*precision*recall / (precision + recall)\n",
    "  except:\n",
    "    fscore = 0\n",
    "  try:\n",
    "    accuracy = (true_pos + true_neg) / float(len(gold))\n",
    "  except:\n",
    "    accuracy = 0\n",
    "  return accuracy, precision, recall, fscore"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
